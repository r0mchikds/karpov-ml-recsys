{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлечение эмбеддингов постов с помощью DistilBERT\n",
    "\n",
    "**Цель ноутбука.**  \n",
    "Создать текстовые эмбеддинги для постов социальной сети на основе предобученной языковой модели **DistilBERT**, и сократить их размерность методом **PCA** и сохранить результат для последующего обучения модели рекомендаций.\n",
    "\n",
    "**Входные данные:**  \n",
    "- `post.csv` — таблица с полями `post_id`, `text`, `topic`.\n",
    "\n",
    "**Выходные данные:**  \n",
    "- `embeddings_post.csv` — 20-мерные BERT-эмбеддинги постов (`pca_bert_1`–`pca_bert_20`).\n",
    "\n",
    "**Этапы:**  \n",
    "1. Импорт библиотек и загрузка данных.  \n",
    "2. Токенизация текстов и подготовка датасета.  \n",
    "3. Извлечение эмбеддингов через `DistilBertModel`.  \n",
    "4. Снижение размерности до 20 компонент с помощью PCA.  \n",
    "5. Сохранение итогового датафрейма.\n",
    "\n",
    "> Все вычисления выполняются без изменения архитектуры модели, используется предобученный чекпойнт `distilbert-base-cased`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Администратор\\Desktop\\START_ML\\Karpov_Courses_pet\\Deep_learning\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Импортируем основные библиотеки для работы с PyTorch, трансформерами и обработкой данных\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>UK economy facing major risks\\n\\nThe UK manufa...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aids and climate top Davos agenda\\n\\nClimate c...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Asian quake hits European shares\\n\\nShares in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India power shares jump on debut\\n\\nShares in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lacroix label bought by US firm\\n\\nLuxury good...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                               text     topic\n",
       "0        1  UK economy facing major risks\\n\\nThe UK manufa...  business\n",
       "1        2  Aids and climate top Davos agenda\\n\\nClimate c...  business\n",
       "2        3  Asian quake hits European shares\\n\\nShares in ...  business\n",
       "3        4  India power shares jump on debut\\n\\nShares in ...  business\n",
       "4        5  Lacroix label bought by US firm\\n\\nLuxury good...  business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем таблицу постов\n",
    "post = pd.read_csv(\"post.csv\")\n",
    "post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем токенайзер и модель DistilBERT\n",
    "checkpoint = \"distilbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = DistilBertModel.from_pretrained(checkpoint)\n",
    "\n",
    "# Определяем устройство (GPU, если доступен)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс-обёртка для датасета постов, возвращает токенизированный текст\n",
    "class PostDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.tokenizer(\n",
    "            self.texts[index],\n",
    "            padding=False,\n",
    "            truncation=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем DataLoader для последовательной обработки батчами\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "dataset = PostDataset(post[\"text\"].tolist(), tokenizer)\n",
    "loader = DataLoader(dataset, batch_size=64, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для извлечения CLS-эмбеддингов из DistilBERT\n",
    "@torch.inference_mode()\n",
    "def get_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        # Используем [CLS]-токен в качестве представления текста\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embeddings.cpu())\n",
    "    \n",
    "    return torch.cat(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:52<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7023, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Извлекаем эмбеддинги для всех постов\n",
    "embeddings = get_embeddings(model, loader)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.78907362,  1.57899475,  1.4211591 , ..., -0.03371233,\n",
       "        -0.58001961, -0.00612047],\n",
       "       [-0.7927638 ,  1.52105614,  0.89774562, ...,  0.3261879 ,\n",
       "        -0.13357319, -0.33769165],\n",
       "       [-0.80129194,  1.22360769,  0.66945213, ..., -0.07861749,\n",
       "        -0.77339762,  0.17103792],\n",
       "       ...,\n",
       "       [ 0.46940024, -0.87485698, -0.48207698, ...,  0.2974304 ,\n",
       "        -0.17970886,  0.1804096 ],\n",
       "       [ 1.57979211, -0.44861258, -0.12669208, ..., -0.23992028,\n",
       "         0.22837455,  0.11805765],\n",
       "       [ 0.89446924, -0.53490048, -0.19991385, ...,  0.07923052,\n",
       "         0.44692684,  0.10423737]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Снижаем размерность до 20 компонент PCA для последующего обучения модели\n",
    "pca = PCA(n_components=20)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "reduced_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_bert_1</th>\n",
       "      <th>pca_bert_2</th>\n",
       "      <th>pca_bert_3</th>\n",
       "      <th>pca_bert_4</th>\n",
       "      <th>pca_bert_5</th>\n",
       "      <th>pca_bert_6</th>\n",
       "      <th>pca_bert_7</th>\n",
       "      <th>pca_bert_8</th>\n",
       "      <th>pca_bert_9</th>\n",
       "      <th>pca_bert_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_bert_12</th>\n",
       "      <th>pca_bert_13</th>\n",
       "      <th>pca_bert_14</th>\n",
       "      <th>pca_bert_15</th>\n",
       "      <th>pca_bert_16</th>\n",
       "      <th>pca_bert_17</th>\n",
       "      <th>pca_bert_18</th>\n",
       "      <th>pca_bert_19</th>\n",
       "      <th>pca_bert_20</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.789074</td>\n",
       "      <td>1.578995</td>\n",
       "      <td>1.421159</td>\n",
       "      <td>0.292831</td>\n",
       "      <td>0.196380</td>\n",
       "      <td>0.482332</td>\n",
       "      <td>-0.172336</td>\n",
       "      <td>0.252792</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>-0.029784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.536405</td>\n",
       "      <td>0.113529</td>\n",
       "      <td>0.143566</td>\n",
       "      <td>0.053079</td>\n",
       "      <td>0.060490</td>\n",
       "      <td>-0.177239</td>\n",
       "      <td>-0.033712</td>\n",
       "      <td>-0.580020</td>\n",
       "      <td>-0.006120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.792764</td>\n",
       "      <td>1.521056</td>\n",
       "      <td>0.897746</td>\n",
       "      <td>-0.228620</td>\n",
       "      <td>0.109591</td>\n",
       "      <td>-0.125362</td>\n",
       "      <td>-0.163190</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>-0.349708</td>\n",
       "      <td>-0.423531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690819</td>\n",
       "      <td>0.125367</td>\n",
       "      <td>0.447225</td>\n",
       "      <td>-0.153495</td>\n",
       "      <td>0.281642</td>\n",
       "      <td>0.264169</td>\n",
       "      <td>0.326188</td>\n",
       "      <td>-0.133573</td>\n",
       "      <td>-0.337692</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.801292</td>\n",
       "      <td>1.223608</td>\n",
       "      <td>0.669452</td>\n",
       "      <td>-1.323420</td>\n",
       "      <td>-0.081454</td>\n",
       "      <td>-0.550803</td>\n",
       "      <td>0.049824</td>\n",
       "      <td>0.241455</td>\n",
       "      <td>-0.509045</td>\n",
       "      <td>-0.007866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182175</td>\n",
       "      <td>0.202675</td>\n",
       "      <td>-0.066136</td>\n",
       "      <td>0.210822</td>\n",
       "      <td>0.072629</td>\n",
       "      <td>-0.023954</td>\n",
       "      <td>-0.078617</td>\n",
       "      <td>-0.773398</td>\n",
       "      <td>0.171038</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.867122</td>\n",
       "      <td>0.971222</td>\n",
       "      <td>1.577188</td>\n",
       "      <td>-0.833192</td>\n",
       "      <td>0.841209</td>\n",
       "      <td>0.292207</td>\n",
       "      <td>0.742447</td>\n",
       "      <td>-0.886750</td>\n",
       "      <td>-0.494585</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230937</td>\n",
       "      <td>-0.453456</td>\n",
       "      <td>0.290870</td>\n",
       "      <td>0.044735</td>\n",
       "      <td>-0.518971</td>\n",
       "      <td>-0.258113</td>\n",
       "      <td>0.583832</td>\n",
       "      <td>-0.053154</td>\n",
       "      <td>-0.287652</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.411659</td>\n",
       "      <td>0.809849</td>\n",
       "      <td>0.682362</td>\n",
       "      <td>-0.790953</td>\n",
       "      <td>-0.186110</td>\n",
       "      <td>0.596705</td>\n",
       "      <td>0.169838</td>\n",
       "      <td>0.758098</td>\n",
       "      <td>-0.193135</td>\n",
       "      <td>0.064067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>-0.300151</td>\n",
       "      <td>-0.287257</td>\n",
       "      <td>0.124016</td>\n",
       "      <td>-0.170200</td>\n",
       "      <td>-0.403123</td>\n",
       "      <td>-0.233267</td>\n",
       "      <td>0.087435</td>\n",
       "      <td>0.026991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>0.983509</td>\n",
       "      <td>-0.483879</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.066758</td>\n",
       "      <td>0.059189</td>\n",
       "      <td>-0.342647</td>\n",
       "      <td>0.026161</td>\n",
       "      <td>0.575154</td>\n",
       "      <td>-0.049793</td>\n",
       "      <td>0.668213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143204</td>\n",
       "      <td>-0.063735</td>\n",
       "      <td>0.365156</td>\n",
       "      <td>-0.025876</td>\n",
       "      <td>0.116609</td>\n",
       "      <td>-0.394875</td>\n",
       "      <td>0.124753</td>\n",
       "      <td>-0.223166</td>\n",
       "      <td>-0.039118</td>\n",
       "      <td>7315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>0.821776</td>\n",
       "      <td>-0.706064</td>\n",
       "      <td>0.164485</td>\n",
       "      <td>0.391023</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>-0.233316</td>\n",
       "      <td>0.336846</td>\n",
       "      <td>0.425709</td>\n",
       "      <td>0.112211</td>\n",
       "      <td>0.308368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033479</td>\n",
       "      <td>-0.205864</td>\n",
       "      <td>-0.291056</td>\n",
       "      <td>-0.178710</td>\n",
       "      <td>-0.052942</td>\n",
       "      <td>0.198309</td>\n",
       "      <td>-0.113324</td>\n",
       "      <td>-0.149379</td>\n",
       "      <td>0.052039</td>\n",
       "      <td>7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>0.469400</td>\n",
       "      <td>-0.874857</td>\n",
       "      <td>-0.482077</td>\n",
       "      <td>0.138474</td>\n",
       "      <td>-0.257596</td>\n",
       "      <td>-0.545992</td>\n",
       "      <td>-0.031882</td>\n",
       "      <td>0.287168</td>\n",
       "      <td>-0.504227</td>\n",
       "      <td>0.519209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044093</td>\n",
       "      <td>-0.063617</td>\n",
       "      <td>-0.193567</td>\n",
       "      <td>-0.108290</td>\n",
       "      <td>-0.130713</td>\n",
       "      <td>0.403388</td>\n",
       "      <td>0.297430</td>\n",
       "      <td>-0.179709</td>\n",
       "      <td>0.180410</td>\n",
       "      <td>7317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>1.579792</td>\n",
       "      <td>-0.448613</td>\n",
       "      <td>-0.126692</td>\n",
       "      <td>-0.100854</td>\n",
       "      <td>0.284518</td>\n",
       "      <td>0.370505</td>\n",
       "      <td>-0.190609</td>\n",
       "      <td>0.049485</td>\n",
       "      <td>-0.189625</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288475</td>\n",
       "      <td>-0.277857</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>-0.071188</td>\n",
       "      <td>0.129983</td>\n",
       "      <td>-0.086229</td>\n",
       "      <td>-0.239920</td>\n",
       "      <td>0.228375</td>\n",
       "      <td>0.118058</td>\n",
       "      <td>7318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>0.894469</td>\n",
       "      <td>-0.534900</td>\n",
       "      <td>-0.199914</td>\n",
       "      <td>-0.521649</td>\n",
       "      <td>-0.014382</td>\n",
       "      <td>-0.511432</td>\n",
       "      <td>-0.252087</td>\n",
       "      <td>-0.414823</td>\n",
       "      <td>-0.226344</td>\n",
       "      <td>-0.789543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106662</td>\n",
       "      <td>0.206681</td>\n",
       "      <td>-0.326948</td>\n",
       "      <td>-0.032800</td>\n",
       "      <td>0.159957</td>\n",
       "      <td>0.430588</td>\n",
       "      <td>0.079231</td>\n",
       "      <td>0.446927</td>\n",
       "      <td>0.104237</td>\n",
       "      <td>7319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7023 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pca_bert_1  pca_bert_2  pca_bert_3  pca_bert_4  pca_bert_5  pca_bert_6  \\\n",
       "0      -0.789074    1.578995    1.421159    0.292831    0.196380    0.482332   \n",
       "1      -0.792764    1.521056    0.897746   -0.228620    0.109591   -0.125362   \n",
       "2      -0.801292    1.223608    0.669452   -1.323420   -0.081454   -0.550803   \n",
       "3      -0.867122    0.971222    1.577188   -0.833192    0.841209    0.292207   \n",
       "4      -0.411659    0.809849    0.682362   -0.790953   -0.186110    0.596705   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "7018    0.983509   -0.483879   -0.001963   -0.066758    0.059189   -0.342647   \n",
       "7019    0.821776   -0.706064    0.164485    0.391023    0.029565   -0.233316   \n",
       "7020    0.469400   -0.874857   -0.482077    0.138474   -0.257596   -0.545992   \n",
       "7021    1.579792   -0.448613   -0.126692   -0.100854    0.284518    0.370505   \n",
       "7022    0.894469   -0.534900   -0.199914   -0.521649   -0.014382   -0.511432   \n",
       "\n",
       "      pca_bert_7  pca_bert_8  pca_bert_9  pca_bert_10  ...  pca_bert_12  \\\n",
       "0      -0.172336    0.252792    0.128668    -0.029784  ...    -0.536405   \n",
       "1      -0.163190   -0.005947   -0.349708    -0.423531  ...     0.690819   \n",
       "2       0.049824    0.241455   -0.509045    -0.007866  ...    -0.182175   \n",
       "3       0.742447   -0.886750   -0.494585     0.055655  ...     0.230937   \n",
       "4       0.169838    0.758098   -0.193135     0.064067  ...    -0.007051   \n",
       "...          ...         ...         ...          ...  ...          ...   \n",
       "7018    0.026161    0.575154   -0.049793     0.668213  ...     0.143204   \n",
       "7019    0.336846    0.425709    0.112211     0.308368  ...    -0.033479   \n",
       "7020   -0.031882    0.287168   -0.504227     0.519209  ...    -0.044093   \n",
       "7021   -0.190609    0.049485   -0.189625     0.021933  ...    -0.288475   \n",
       "7022   -0.252087   -0.414823   -0.226344    -0.789543  ...    -0.106662   \n",
       "\n",
       "      pca_bert_13  pca_bert_14  pca_bert_15  pca_bert_16  pca_bert_17  \\\n",
       "0        0.113529     0.143566     0.053079     0.060490    -0.177239   \n",
       "1        0.125367     0.447225    -0.153495     0.281642     0.264169   \n",
       "2        0.202675    -0.066136     0.210822     0.072629    -0.023954   \n",
       "3       -0.453456     0.290870     0.044735    -0.518971    -0.258113   \n",
       "4       -0.300151    -0.287257     0.124016    -0.170200    -0.403123   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "7018    -0.063735     0.365156    -0.025876     0.116609    -0.394875   \n",
       "7019    -0.205864    -0.291056    -0.178710    -0.052942     0.198309   \n",
       "7020    -0.063617    -0.193567    -0.108290    -0.130713     0.403388   \n",
       "7021    -0.277857     0.454060    -0.071188     0.129983    -0.086229   \n",
       "7022     0.206681    -0.326948    -0.032800     0.159957     0.430588   \n",
       "\n",
       "      pca_bert_18  pca_bert_19  pca_bert_20  post_id  \n",
       "0       -0.033712    -0.580020    -0.006120        1  \n",
       "1        0.326188    -0.133573    -0.337692        2  \n",
       "2       -0.078617    -0.773398     0.171038        3  \n",
       "3        0.583832    -0.053154    -0.287652        4  \n",
       "4       -0.233267     0.087435     0.026991        5  \n",
       "...           ...          ...          ...      ...  \n",
       "7018     0.124753    -0.223166    -0.039118     7315  \n",
       "7019    -0.113324    -0.149379     0.052039     7316  \n",
       "7020     0.297430    -0.179709     0.180410     7317  \n",
       "7021    -0.239920     0.228375     0.118058     7318  \n",
       "7022     0.079231     0.446927     0.104237     7319  \n",
       "\n",
       "[7023 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Формируем датафрейм с эмбеддингами и id поста\n",
    "embedding_df = pd.DataFrame(reduced_embeddings, \n",
    "                            columns=(f\"pca_bert_{i+1}\" for i in range(20)))\n",
    "embedding_df['post_id'] = post['post_id'].values\n",
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем результат в CSV для использования в следующих этапах\n",
    "embedding_df.to_csv(\"embeddings_post.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги ноутбука\n",
    "\n",
    "- Сгенерированы эмбеддинги постов на основе `DistilBERT`.  \n",
    "- Размерность снижена до 20 компонент с помощью `PCA`.  \n",
    "- Результат сохранён в файл `embeddings_post.csv`.\n",
    "\n",
    "**Зачем это нужно:**  \n",
    "Полученные эмбеддинги использоваться как признаки `post_features` при обучении рекомендательной модели.\n",
    "\n",
    "**Следующие шаги:**  \n",
    "- объединить эти эмбеддинги с таблицами `user` и `feed`;  \n",
    "- обучить модель, предсказывающую вероятность лайка (`target=1`);  \n",
    "- оценить качество по `Hitrate@5`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
